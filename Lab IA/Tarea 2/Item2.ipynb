{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dc4a510",
   "metadata": {},
   "source": [
    "\n",
    "## Item 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae0c8e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f011a22",
   "metadata": {},
   "source": [
    "Se procede a cargar el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9aaf3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    data = fetch_california_housing()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9626bf4d",
   "metadata": {},
   "source": [
    "Se sigue con el preprocesamiento, que asegura que los datos estén en una forma adecuada para ser alimentados a los modelos. Se escalan las características, ya que los modelos basados en gradientes (como SVM y Regresión Logística) se benefician de tener datos escalados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f067da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preprocessor(df, target, cfg):\n",
    "    y = df[target]\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "\n",
    "    transformers = []\n",
    "\n",
    "    if num_cols:\n",
    "        steps_num = [(\"imputer\", SimpleImputer(strategy=cfg[\"impute_strategy_num\"]))]\n",
    "        if cfg[\"scale_numeric\"]:\n",
    "            steps_num.append((\"scaler\", StandardScaler()))\n",
    "        transformers.append((\"num\", Pipeline(steps=steps_num), num_cols))\n",
    "\n",
    "    if cat_cols and cfg[\"one_hot_encode\"]:\n",
    "        transformers.append((\"cat\", Pipeline(steps=[\n",
    "                                 (\"imputer\", SimpleImputer(strategy=cfg[\"impute_strategy_cat\"])),\n",
    "                                 (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False))\n",
    "                             ]), cat_cols))\n",
    "    pre = ColumnTransformer(transformers=transformers)\n",
    "    return X, y, pre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a4aad0",
   "metadata": {},
   "source": [
    "La función build_sgd_classifier se encarga de crear un modelo de SGDClassifier configurado con los hiperparámetros proporcionados en el archivo YAML. Usa partial_fit para inicializar el modelo y permitir que se entrene de manera incremental. Es ideal para entrenar el modelo de manera eficiente en un entorno de aprendizaje en línea o entrenamiento por lotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc75d958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sgd_classifier(cfg, classes_):\n",
    "    clf = SGDClassifier(\n",
    "        loss=cfg[\"loss\"],\n",
    "        learning_rate=cfg[\"learning_rate\"],\n",
    "        eta0=cfg[\"eta0\"],\n",
    "        alpha=cfg.get(\"alpha\", 0.0001),\n",
    "        penalty=cfg.get(\"penalty\", \"l2\"),\n",
    "        random_state=cfg.get(\"seed\", 42),\n",
    "        early_stopping=False,      \n",
    "        warm_start=True,\n",
    "        max_iter=1,                \n",
    "        tol=None\n",
    "    )\n",
    "    clf.partial_fit(np.zeros((1, classes_.shape[0])), classes=classes_)\n",
    "    return clf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8b2f4f",
   "metadata": {},
   "source": [
    "Luego se entrena el modelo SGDClassifier por una única época usando lotes de tamaño configurable. Es una forma eficiente de entrenar el modelo de manera incremental, lo cual es útil cuando estás ajustando varios modelos con diferentes configuraciones o en datasets grandes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44c40a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(clf, X_train, y_train, batch_size=256, shuffle=True, classes_=None):\n",
    "    n = X_train.shape[0]\n",
    "    idx = np.arange(n)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(idx)\n",
    "    for start in range(0, n, batch_size):\n",
    "        end = min(start + batch_size, n)\n",
    "        batch_idx = idx[start:end]\n",
    "        clf.partial_fit(X_train[batch_idx], y_train[batch_idx], classes=classes_)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb2171c",
   "metadata": {},
   "source": [
    "Después, se evalúa el desempeño de un modelo durante el entrenamiento, basándose en métricas específicas. El resultado de esta evaluación se utiliza para decidir qué configuraciones de modelo deben ser descartadas (culling) durante el proceso de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31bb02d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_for_culling(model_type, clf, X, y, scoring=\"neg_mean_squared_error\"):\n",
    "    if scoring == \"neg_mean_squared_error\":\n",
    "        y_pred = clf.predict(X)\n",
    "        return -mean_squared_error(y, y_pred)\n",
    "    elif scoring == \"r2\":\n",
    "        y_pred = clf.predict(X)\n",
    "        return r2_score(y, y_pred)\n",
    "    else:\n",
    "        return r2_score(y, clf.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7dbd9d",
   "metadata": {},
   "source": [
    "Luego se entrenar un solo modelo por una época utilizando un lote de datos (batch), para luego devolver el modelo entrenado junto con su nombre. Es una función auxiliar que se usa en procesos de entrenamiento en paralelo, especialmente cuando entrenamos múltiples modelos con diferentes configuraciones de hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd5d71a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_epoch_job(model_pack, X_train, y_train, batch_size, shuffle, classes_):\n",
    "    name, clf = model_pack[\"name\"], model_pack[\"model\"]\n",
    "    clf = train_one_epoch(clf, X_train, y_train, batch_size=batch_size, shuffle=shuffle, classes_=classes_)\n",
    "    return {\"name\": name, \"model\": clf}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc91706",
   "metadata": {},
   "source": [
    "La siguiente función entrena múltiples configuraciones de modelos en paralelo y realiza un proceso de \"culling\" (eliminación de modelos con peor desempeño) cada cierto número de épocas. El objetivo es mantener solo las mejores configuraciones de modelos y entrenarlas hasta el final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b16216c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_culling(\n",
    "    model_type, configs, X_train, y_train, classes_,\n",
    "    batch_size=256, shuffle=True, max_epochs=50, eval_every=5, scoring=\"neg_mean_squared_error\", n_jobs=-1):\n",
    "    active = []\n",
    "    for cfg in configs:\n",
    "        clf = build_sgd_classifier(cfg, classes_)\n",
    "        active.append({\"name\": cfg[\"name\"], \"cfg\": cfg, \"model\": clf, \"history\": []})\n",
    "\n",
    "    epoch = 0\n",
    "    while epoch < max_epochs and len(active) > 1:\n",
    "        results = Parallel(n_jobs=n_jobs)(delayed(_train_epoch_job)(m, X_train, y_train, batch_size, shuffle, classes_) for m in active)\n",
    "        for i, res in enumerate(results):\n",
    "            active[i][\"model\"] = res[\"model\"]\n",
    "        epoch += 1\n",
    "        if epoch % eval_every == 0:\n",
    "            scores = []\n",
    "            for m in active:\n",
    "                s = score_for_culling(model_type, m[\"model\"], X_train, y_train, scoring=scoring)\n",
    "                m[\"history\"].append({\"epoch\": epoch, \"score\": s})\n",
    "                scores.append((m[\"name\"], s))\n",
    "            worst = min(scores, key=lambda x: x[1])\n",
    "            active = [m for m in active if m[\"name\"] != worst[0]]\n",
    "    \n",
    "    active.sort(key=lambda m: m[\"history\"][-1][\"score\"], reverse=True)\n",
    "    return active"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c0acbd",
   "metadata": {},
   "source": [
    "La siguiente función se encarga de evaluar el desempeño de un modelo utilizando el conjunto de test (datos que el modelo no ha visto durante el entrenamiento). Calcula dos métricas comunes en  regresión, MSE (Error Cuadrático Medio) y R² (Coeficiente de Determinación)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51f43370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_metrics(clf, X_test, y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    return {\n",
    "        \"MSE\": mean_squared_error(y_test, y_pred),\n",
    "        \"R2\": r2_score(y_test, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb3aa37",
   "metadata": {},
   "source": [
    "Seguido de esto, se comienza la función main."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed5f5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Se carga yaml y datos a utilizar, preprocesando los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dd43568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    with open(\"configs/experiment.yaml\", \"r\") as f:\n",
    "        cfg = yaml.safe_load(f)\n",
    "\n",
    "    data = load_dataset()\n",
    "    X = data.data\n",
    "    y = data.target\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    classes_ = np.unique(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1e75fa",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
